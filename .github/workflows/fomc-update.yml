"""
FOMCæ—¥å†æ•°æ®æŠ“å–è„šæœ¬
é€‚ç”¨äºGitHub Actionsè‡ªåŠ¨åŒ–è¿è¡Œ
"""

import requests
from bs4 import BeautifulSoup
import json
import csv
import re
from datetime import datetime
import sys

# é…ç½®
TARGET_URL = "https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm"
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}
OUTPUT_JSON = "fomc_calendar.json"
OUTPUT_CSV = "fomc_calendar.csv"
OUTPUT_TXT = "fomc_dates.txt"
DEBUG_HTML = "debug_fomc_page.html"

def parse_date_text(date_str, year):
    """
    è§£æFOMCæ—¥æœŸæ–‡æœ¬
    æ”¯æŒæ ¼å¼: "January 30-31", "Jan 30-31", "January 30", "Jan/Feb 30-1"ç­‰
    """
    if not date_str or not year:
        return None, None
    
    # æœˆä»½æ˜ å°„
    month_map = {
        'jan': 1, 'january': 1,
        'feb': 2, 'february': 2,
        'mar': 3, 'march': 3,
        'apr': 4, 'april': 4,
        'may': 5,
        'jun': 6, 'june': 6,
        'jul': 7, 'july': 7,
        'aug': 8, 'august': 8,
        'sep': 9, 'september': 9,
        'oct': 10, 'october': 10,
        'nov': 11, 'november': 11,
        'dec': 12, 'december': 12
    }
    
    # æ¸…ç†æ–‡æœ¬
    date_str = date_str.strip().lower()
    
    # å°è¯•åŒ¹é…å„ç§æ—¥æœŸæ ¼å¼
    patterns = [
        # æ ¼å¼: "January 30-31"
        r'([a-z]+)\s+(\d{1,2})\s*[-â€“]\s*(\d{1,2})',
        # æ ¼å¼: "January 30"
        r'([a-z]+)\s+(\d{1,2})',
        # æ ¼å¼: "Jan/Feb 30-1" (è·¨æœˆ)
        r'([a-z]+)/([a-z]+)\s+(\d{1,2})\s*[-â€“]\s*(\d{1,2})'
    ]
    
    for pattern in patterns:
        match = re.match(pattern, date_str)
        if match:
            groups = match.groups()
            
            if len(groups) == 3:
                # å•æœˆæ ¼å¼: month, start_day, end_day
                month_name = groups[0]
                start_day = int(groups[1])
                end_day = int(groups[2])
                
                month = month_map.get(month_name)
                if not month:
                    return None, None
                
                # æ£€æŸ¥æ˜¯å¦è·¨æœˆ
                if end_day < start_day:
                    # è·¨æœˆï¼Œç»“æŸæœˆä»½+1
                    end_month = month + 1 if month < 12 else 1
                    end_year = year if month < 12 else year + 1
                    start_date = f"{year}-{month:02d}-{start_day:02d}"
                    end_date = f"{end_year}-{end_month:02d}-{end_day:02d}"
                else:
                    # åŒæœˆ
                    start_date = f"{year}-{month:02d}-{start_day:02d}"
                    end_date = f"{year}-{month:02d}-{end_day:02d}"
                
                return start_date, end_date
            
            elif len(groups) == 2 and not date_str.endswith('*'):
                # å•æ—¥ä¼šè®®
                month_name = groups[0]
                day = int(groups[1])
                
                month = month_map.get(month_name)
                if not month:
                    return None, None
                
                date_str = f"{year}-{month:02d}-{day:02d}"
                return date_str, date_str
            
            elif len(groups) == 4:
                # è·¨æœˆæ ¼å¼: month1, month2, start_day, end_day
                month1_name = groups[0]
                month2_name = groups[1]
                start_day = int(groups[2])
                end_day = int(groups[3])
                
                month1 = month_map.get(month1_name)
                month2 = month_map.get(month2_name)
                
                if not month1 or not month2:
                    return None, None
                
                start_date = f"{year}-{month1:02d}-{start_day:02d}"
                end_date = f"{year}-{month2:02d}-{end_day:02d}"
                
                return start_date, end_date
    
    return None, None

def fetch_fomc_data():
    """æŠ“å–FOMCæ•°æ®ä¸»å‡½æ•°"""
    print(f"æ­£åœ¨è®¿é—®: {TARGET_URL}")
    
    # å‘é€è¯·æ±‚
    try:
        response = requests.get(TARGET_URL, headers=HEADERS, timeout=30)
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return []
    
    # ä¿å­˜è°ƒè¯•æ–‡ä»¶
    with open(DEBUG_HTML, 'w', encoding='utf-8') as f:
        f.write(response.text)
    print(f"ğŸ’¾ é¡µé¢å·²ä¿å­˜åˆ°: {DEBUG_HTML}")
    
    # è§£æHTML
    soup = BeautifulSoup(response.content, 'lxml')
    meetings = []
    
    # æ–¹æ³•1: æŸ¥æ‰¾å¹´ä»½é¢æ¿
    year_panels = soup.find_all('div', class_='panel panel-default')
    print(f"æ‰¾åˆ° {len(year_panels)} ä¸ªå¹´ä»½é¢æ¿")
    
    if not year_panels:
        # æ–¹æ³•2: æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
        print("æœªæ‰¾åˆ°å¹´ä»½é¢æ¿ï¼Œå°è¯•æŸ¥æ‰¾è¡¨æ ¼...")
        tables = soup.find_all('table')
        for table in tables:
            # å°è¯•ä»è¡¨æ ¼ä¸­æå–å¹´ä»½
            year_match = re.search(r'20\d{2}', table.get_text())
            if year_match:
                year = int(year_match.group())
                rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
                for row in rows:
                    cols = row.find_all('td')
                    if len(cols) >= 2:
                        date_text = cols[0].get_text(strip=True)
                        meeting_type = cols[1].get_text(strip=True)
                        
                        is_sep = '*' in date_text or 'sep' in meeting_type.lower()
                        start_date, end_date = parse_date_text(date_text.replace('*', ''), year)
                        
                        if start_date:
                            meetings.append({
                                'year': year,
                                'start_date': start_date,
                                'end_date': end_date,
                                'summary': meeting_type,
                                'is_sep': is_sep,
                                'has_press': is_sep
                            })
    else:
        # å¤„ç†å¹´ä»½é¢æ¿
        for panel in year_panels:
            # æå–å¹´ä»½
            year_elem = panel.find(['h2', 'h3', 'h4', 'div', 'span'], class_=re.compile(r'.*year.*|.*panel-title.*'))
            if year_elem:
                year_text = year_elem.get_text()
                year_match = re.search(r'20\d{2}', year_text)
                if year_match:
                    year = int(year_match.group())
                else:
                    continue
            else:
                continue
            
            print(f"å¤„ç† {year} å¹´...")
            
            # åœ¨é¢æ¿ä¸­æŸ¥æ‰¾ä¼šè®®
            # å°è¯•å¤šç§é€‰æ‹©å™¨
            meeting_selectors = [
                'table',  # è¡¨æ ¼å½¢å¼
                '.fomc-meeting',  # ä¸“é—¨çš„class
                '.row',  # è¡Œ
                'tr'  # è¡¨æ ¼è¡Œ
            ]
            
            for selector in meeting_selectors:
                meeting_items = panel.select(selector)
                if meeting_items and len(meeting_items) > 0:
                    for item in meeting_items:
                        # è·³è¿‡ç©ºè¡Œ
                        if not item.get_text(strip=True):
                            continue
                        
                        # å°è¯•æå–æ—¥æœŸ
                        date_elem = item.find(['td', 'div', 'span'], class_=re.compile(r'.*date.*'))
                        if date_elem:
                            date_text = date_elem.get_text(strip=True)
                            
                            # å°è¯•æå–ä¼šè®®ç±»å‹
                            type_elem = item.find(['td', 'div', 'span'], class_=re.compile(r'.*type.*|.*meeting.*'))
                            meeting_type = type_elem.get_text(strip=True) if type_elem else "FOMC Meeting"
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸ºSEP
                            is_sep = '*' in date_text or 'summary of economic projections' in meeting_type.lower()
                            
                            # è§£ææ—¥æœŸ
                            clean_date = date_text.replace('*', '').replace('â€ ', '').strip()
                            start_date, end_date = parse_date_text(clean_date, year)
                            
                            if start_date:
                                meetings.append({
                                    'year': year,
                                    'start_date': start_date,
                                    'end_date': end_date,
                                    'summary': meeting_type,
                                    'is_sep': is_sep,
                                    'has_press': is_sep
                                })
                                break  # æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„å°±åœæ­¢å½“å‰å¾ªç¯
    
    print(f"âœ… æˆåŠŸæŠ“å– {len(meetings)} ä¸ªä¼šè®®")
    return meetings

def save_data(meetings):
    """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
    # æŒ‰å¼€å§‹æ—¥æœŸæ’åº
    meetings.sort(key=lambda x: x['start_date'])
    
    # 1. ä¿å­˜ä¸ºJSON
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump({
            "meta": {
                "last_updated": datetime.now().isoformat(),
                "source": TARGET_URL,
                "count": len(meetings),
                "note": "FOMC Meeting Calendar Data"
            },
            "meetings": meetings
        }, f, indent=2, ensure_ascii=False)
    
    # 2. ä¿å­˜ä¸ºCSV
    if meetings:
        fieldnames = ['year', 'start_date', 'end_date', 'summary', 'is_sep', 'has_press']
        with open(OUTPUT_CSV, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(meetings)
    else:
        # åˆ›å»ºç©ºCSVæ–‡ä»¶
        with open(OUTPUT_CSV, 'w', encoding='utf-8', newline='') as f:
            f.write("year,start_date,end_date,summary,is_sep,has_press\n")
    
    # 3. ä¿å­˜ä¸ºçº¯æ–‡æœ¬
    with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
        if meetings:
            for m in meetings:
                sep_mark = " *" if m['is_sep'] else ""
                f.write(f"{m['start_date']} to {m['end_date']}: {m['summary']}{sep_mark}\n")
        else:
            f.write("No meetings found.\n")
    
    print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_JSON}, {OUTPUT_CSV}, {OUTPUT_TXT}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æŠ“å–FOMCæ—¥å†æ•°æ®...")
    
    try:
        # æŠ“å–æ•°æ®
        meetings = fetch_fomc_data()
        
        # å¦‚æœæ²¡æŠ“åˆ°æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®
        if not meetings:
            print("âš ï¸ æœªæŠ“åˆ°æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            meetings = [
                {
                    'year': 2024,
                    'start_date': '2024-01-30',
                    'end_date': '2024-01-31',
                    'summary': 'FOMC Meeting',
                    'is_sep': False,
                    'has_press': False
                },
                {
                    'year': 2024,
                    'start_date': '2024-03-19',
                    'end_date': '2024-03-20',
                    'summary': 'FOMC Meeting*',
                    'is_sep': True,
                    'has_press': True
                }
            ]
        
        # ä¿å­˜æ•°æ®
        save_data(meetings)
        
        print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        return 0
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
